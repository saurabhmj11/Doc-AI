# Ultra Doc-Intelligence Environment Variables

# Google Gemini API Key (required for LLM features)
GEMINI_API_KEY=your_gemini_api_key_here

# LLM Configuration
# Options: 'online' (Gemini) or 'offline' (Ollama)
LLM_MODE=online
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Server configuration
HOST=0.0.0.0
PORT=8000
DEBUG=true

# Document processing
MAX_FILE_SIZE_MB=10
CHUNK_SIZE=512
CHUNK_OVERLAP=50

# Retrieval settings
TOP_K_RETRIEVAL=10
TOP_K_RERANK=3
SIMILARITY_THRESHOLD=0.3

# Confidence thresholds
HIGH_CONFIDENCE_THRESHOLD=0.8
LOW_CONFIDENCE_THRESHOLD=0.5
GROUNDING_COVERAGE_THRESHOLD=0.6

# API Error Handling
RETRY_ATTEMPTS=3
RETRY_BASE_DELAY=2.0
CIRCUIT_BREAKER_THRESHOLD=5
CIRCUIT_BREAKER_TIMEOUT=60
ENABLE_EXTRACTIVE_FALLBACK=true

# Logging
LOG_LEVEL=INFO
LOG_API_FAILURES=true
LOG_FILE=./logs/api_errors.log

# Reranking
ENABLE_RERANKING=true
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
RERANKER_BATCH_SIZE=32
