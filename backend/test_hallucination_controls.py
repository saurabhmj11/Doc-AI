
import sys
import os
import asyncio
from pathlib import Path

# Add backend to python path
sys.path.append(os.getcwd())
sys.path.append(os.path.join(os.getcwd(), 'backend'))

from dotenv import load_dotenv
load_dotenv("backend/.env")

from backend.config import get_settings
from core.document_processor import DocumentProcessor
from core.rag_pipeline import RAGPipeline
from core.vector_store import get_vector_store

async def main():
    print("Initializing components for Hallucination Control Test...")
    
    try:
        processor = DocumentProcessor()
        rag = RAGPipeline()
        vector_store = get_vector_store()
    except Exception as e:
        print(f"Error initializing: {e}")
        return
    
    # Debug Settings
    settings = get_settings()
    print(f"\n--- Current Settings ---")
    print(f"Similarity Threshold: {settings.similarity_threshold}")
    print(f"Low Confidence Threshold: {settings.low_confidence_threshold}")
    
    # process the file
    fpath = "sample_docs/bill_of_lading_sample.txt"
    full_path = Path(fpath).resolve()
    
    if not full_path.exists():
        print(f"Error: {fpath} not found")
        return

    print(f"\nProcessing {full_path.name}...")
    try:
        doc_id, chunks = processor.process_file(str(full_path), "txt")
        vector_store.add_document(
            document_id=doc_id,
            chunks=chunks,
            filename=full_path.name,
            file_type="txt",
            file_path=str(full_path)
        )
        print(f" - Document added with ID: {doc_id}")
        
    except Exception as e:
        print(f"Error processing file: {e}")
        return

    # Debug Retrieval directly
    print("\n--- Debug Retrieval ---")
    q1_emb = rag.embedding_model.encode("Who is the shipper?", convert_to_numpy=True)
    results = vector_store.search(doc_id, q1_emb, top_k=3)
    print(f"Search Results for 'Who is the shipper?':")
    for r in results:
        print(f" - Score: {r['similarity_score']:.4f} | Text: {r['text'][:50]}...")

    # Test Case 1: Relevant Question (Should be High Confidence)
    q1 = "Who is the shipper?"
    print(f"\n--- Test Case 1: Relevant Question ('{q1}') ---")
    res1 = rag.ask(document_ids=[doc_id], question=q1)
    print(f"Answer: {res1['answer']}")
    print(f"Confidence: {res1['confidence']} ({res1['confidence_level']})")
    print(f"Guardrail Status: {res1['guardrail_status']}")
    
    # Check if fallback was used (heuristic: check for the fallback phrase)
    if "Based on the document, here's the most relevant information" in res1['answer']:
        print("!! WARNING !!: Output appears to be from Extractive Fallback")
    else:
        print("SUCCESS: Output appears to be generated by LLM")

    if res1['guardrail_status'] != 'passed':
        print(f"Guardrail Message: {res1.get('guardrail_message')}")
    
    # Test Case 2: Irrelevant Question (Should be Low Confidence / Refused)
    q2 = "What is the capital of France?"
    print(f"\n--- Test Case 2: Irrelevant Question ('{q2}') ---")
    res2 = rag.ask(document_ids=[doc_id], question=q2)
    print(f"Answer: {res2['answer']}")
    print(f"Confidence: {res2['confidence']} ({res2['confidence_level']})")
    print(f"Guardrail Status: {res2['guardrail_status']}")
    
    # Verify Results
    if res1['guardrail_status'] == 'passed' and (res2['guardrail_status'] != 'passed' or res2['confidence_level'] == 'low'):
        print("\nSUCCESS: Hallucination controls are working as expected.")
    else:
        print("\nWARNING: Hallucination controls might not be behaving as expected.")
        print(f"Test 1 Passed: {res1['guardrail_status'] == 'passed'}")
        print(f"Test 2 Correctly Refused/Low: {res2['guardrail_status'] != 'passed' or res2['confidence_level'] == 'low'}")

if __name__ == "__main__":
    asyncio.run(main())
